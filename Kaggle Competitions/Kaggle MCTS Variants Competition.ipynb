{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a582795-8f79-4463-b5ba-cae9886e8f82",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1><b>UM - Game-Playing Strength of MCTS Variants</b></h1>\n",
    "</center>\n",
    "\n",
    "Predict which variants of Monte-Carlo Tree Search will perform well or poorly against each other in hundreds of board games\n",
    "\n",
    "## Overview\r",
    " \n",
    "In this competition, you’ll create a model to predict how well one Monte-Carlo tree search (MCTS) variant will do against another in a       given game, based on a list of features describing the game. This challenge aims to help us figure out which MCTS variants work best in      different types of games, so we can make more informed choices when applying these algorithms to new problems\n",
    "\n",
    "## Description\r",
    " \n",
    "MCTS is a widely used search algorithm for developing agents that can play board games intelligently. Over the past two decades,             researchers have proposed dozens, if not hundreds, of MCTS variants. Despite this, it's been challenging to determine which variants are     best suited for specific types of games.\r",
    " \n",
    "\r\n",
    "In most studies, researchers demonstrate that a new MCTS variant outperforms one or a few other variants in a limited set of game         s. However, it’s uncommon for a new variant to consistently outperform others across a broad range of games, making it unclear which types   of games certain MCTS variants are best at. Answering this question would greatly improve our understanding of MCTS algorithms, and help     us make better decisions about which variants to apply to new games or other decision-making problems .\r\n",
    "\r\n",
    "This competition challenges you to develop a model that can predict the performance of one MCTS variant against another in a given g    ame, based on the features of the ga me.\r\n",
    "\r\n",
    "Your work could help pave the way for identifying the strengths and weaknesses of different MCTS variants, advancing our understand   ing of where they work best in various sce\n",
    "\n",
    "## Evaluation\r",
    " \n",
    "Submissions are evaluated based on the Root-mean-square-error (RMSE) between predicted and ground-truth performance levels of the first      agent against the second agent.\r",
    "## \n",
    "\r\n",
    "Submitti ng\r\n",
    "You must submit to this competition using the provided Python evaluation API, which serves test set instances in random order in batches  of 100. To use the API, follow the template in this notebook.narios.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061825cb-1c3b-4fd2-8663-3105e366e199",
   "metadata": {},
   "source": [
    "# Version used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829a6f5-a9d8-4d58-9d96-af0aa1b3277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to competition files\n",
    "comp_path = Path('/kaggle/input/um-game-playing-strength-of-mcts-variants')\n",
    "target = 'utility_agent1'\n",
    "\n",
    "# Function to drop columns with a single unique value\n",
    "def drop_single_value_cols(df):\n",
    "    single_value_cols = [col for col in df.columns if df[col].n_unique() == 1]\n",
    "    return df.drop(single_value_cols)\n",
    "\n",
    "# Load training data\n",
    "train = pl.read_csv(comp_path / 'train.csv')\n",
    "y_train = train[target]\n",
    "\n",
    "# Drop columns with single values\n",
    "train = drop_single_value_cols(train)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "cols_to_drop = ['num_draws_agent1', 'num_losses_agent1', 'num_wins_agent1', target]\n",
    "train = train.drop(cols_to_drop)\n",
    "\n",
    "# Encode categorical columns\n",
    "obj_cols = train.select(pl.col(pl.String)).columns\n",
    "enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-999, encoded_missing_value=-9999)\n",
    "enc.fit(train[obj_cols])\n",
    "\n",
    "# Transform the categorical columns in the training data\n",
    "train_transformed = enc.transform(train[obj_cols])\n",
    "for e, c in enumerate(obj_cols):\n",
    "    train = train.with_columns(pl.Series(c, train_transformed[:, e]))\n",
    "\n",
    "# Define models to experiment with (LightGBM and XGBoost)\n",
    "models = {\n",
    "    'lgb': lgb.LGBMRegressor(),\n",
    "    'xgb': xgb.XGBRegressor()\n",
    "}\n",
    "\n",
    "# Parameter grid with num_leaves for LightGBM\n",
    "param_grid = {\n",
    "    'lgb': {\n",
    "        'num_leaves': [31, 50, 100],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 10, 15]\n",
    "    }\n",
    "},\n",
    "    'xgb': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [6, 10],\n",
    "        'min_child_weight': [1, 5]\n",
    "    },\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find the best model and parameters\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    grid = GridSearchCV(model, param_grid[model_name], cv=3, scoring='neg_mean_squared_error')\n",
    "    grid.fit(train, y_train)\n",
    "    best_models[model_name] = grid.best_estimator_\n",
    "    print(f\"Best parameters for {model_name}: {grid.best_params_}\")\n",
    "\n",
    "    # Evaluate using cross-validation\n",
    "    cv_scores = cross_val_score(best_models[model_name], train, y_train, cv=3, scoring='neg_mean_squared_error')\n",
    "    mean_cv_score = -cv_scores.mean()  # Convert negative MSE to positive\n",
    "    print(f\"Mean Cross-Validation MSE for {model_name}: {mean_cv_score}\")\n",
    "\n",
    "# Save the best models for later use\n",
    "joblib.dump(best_models['lgb'], 'best_lgb_model.joblib')\n",
    "joblib.dump(best_models['xgb'], 'best_xgb_model.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de80778e-c98e-4b3b-8a36-485085ec301a",
   "metadata": {},
   "source": [
    "# Versions Submitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98131b9-9bcb-4ec3-98a7-4b71df13a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import kaggle_evaluation.mcts_inference_server as mcts_inference_server\n",
    "\n",
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "# System Configuration\n",
    "class Config:\n",
    "    # Paths to data\n",
    "    train_data_path = Path('/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv')\n",
    "    test_data_path = Path('/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv')\n",
    "    submission_path = Path('/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv')\n",
    "\n",
    "    # Feature engineering configuration\n",
    "    batch_size = 16384\n",
    "    low_memory = True\n",
    "    \n",
    "    # Model parameters\n",
    "    lgb_params = {\n",
    "        'n_estimators': 200,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 20,\n",
    "        'num_leaves': 70,\n",
    "        'n_jobs': -1,\n",
    "        'max_bin': 1024,\n",
    "        'force_row_wise': True\n",
    "    }\n",
    "\n",
    "# Feature Engineering class\n",
    "class FeatureEngineering:\n",
    "    def __init__(self, batch_size, low_memory):\n",
    "        self.batch_size = batch_size\n",
    "        self.low_memory = low_memory\n",
    "        \n",
    "    def drop_unwanted_columns(self, df, columns):\n",
    "        return df.drop(columns, axis=1) if set(columns).issubset(df.columns) else df\n",
    "    \n",
    "    def optimize_dtypes(self, df):\n",
    "        # Setting categorical and numeric data types for optimization\n",
    "        categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "        numeric_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "        df[categorical_cols] = df[categorical_cols].astype('category')\n",
    "        df[numeric_cols] = df[numeric_cols].astype('float32')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def load_and_process(self, file_path, drop_cols=None):\n",
    "        # Loading data with polars for efficiency\n",
    "        df = pl.read_csv(file_path, batch_size=self.batch_size, low_memory=self.low_memory).to_pandas()\n",
    "        \n",
    "        # This is to drop unnecessary columns\n",
    "        if drop_cols:\n",
    "            df = self.drop_unwanted_columns(df, drop_cols)\n",
    "        \n",
    "        # Optimizing data types\n",
    "        df = self.optimize_dtypes(df)\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Initializing feature engineering\n",
    "fe = FeatureEngineering(Config.batch_size, Config.low_memory)\n",
    "\n",
    "# Processing training data and unneeded columns will be dropped\n",
    "train_df = fe.load_and_process(Config.train_data_path, drop_cols=['num_wins_agent1', 'num_draws_agent1', 'num_losses_agent1'])\n",
    "\n",
    "\n",
    "# Model Development class\n",
    "class ModelDevelopment:\n",
    "    def __init__(self, model_params):\n",
    "        self.model_params = model_params\n",
    "        self.models = []\n",
    "    \n",
    "    def kfold_lightgbm(self, X_train, y_train, n_splits=5):\n",
    "        # KFold cross-validation\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        oof_preds = pd.Series(0.0, index=X_train.index)\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n",
    "            print(f'Fold {fold + 1}')\n",
    "            \n",
    "            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            # Initializing LightGBM model\n",
    "            model = lgb.LGBMRegressor(**self.model_params)\n",
    "            \n",
    "            # Model fitting with early stopping callback\n",
    "            model.fit(\n",
    "                X_tr, y_tr,\n",
    "                eval_set=[(X_val, y_val)],\n",
    "                eval_metric='rmse',\n",
    "                callbacks=[early_stopping(stopping_rounds=50, verbose=True)]\n",
    "            )\n",
    "            \n",
    "            # Storing the model for future use\n",
    "            self.models.append(model)\n",
    "            \n",
    "            # Making out-of-fold predictions and cast to float64\n",
    "            oof_preds.iloc[val_idx] = model.predict(X_val).astype(float)\n",
    "        \n",
    "        # Calculating the out-of-fold RMSE score\n",
    "        oof_rmse = mean_squared_error(y_train, oof_preds, squared=False)\n",
    "        print(f'OOF RMSE: {oof_rmse:.4f}')\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        if self.models:\n",
    "            preds = sum([model.predict(X_test) for model in self.models]) / len(self.models)\n",
    "            return preds\n",
    "        else:\n",
    "            raise ValueError(\"Models are not trained yet\")\n",
    "\n",
    "# Initialize model development\n",
    "md = ModelDevelopment(Config.lgb_params)\n",
    "\n",
    "# Training function\n",
    "def train_model():\n",
    "    # Load training data and drop columns\n",
    "    train_df = fe.load_and_process(Config.train_data_path, drop_cols=['num_wins_agent1', 'num_draws_agent1', 'num_losses_agent1'])\n",
    "    \n",
    "    # Defining features and target data\n",
    "    X_train = train_df.drop('utility_agent1', axis=1)\n",
    "    y_train = train_df['utility_agent1']\n",
    "    \n",
    "    # Training the model with KFold\n",
    "    md.kfold_lightgbm(X_train, y_train)\n",
    "    \n",
    "    # Clean up\n",
    "    del train_df\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "# Initializing a counter for prediction calls\n",
    "counter = 0\n",
    "\n",
    "# Defining the predict function for the API\n",
    "def predict(test, submission):\n",
    "    global counter\n",
    "    \n",
    "    # Counter for prediction call    \n",
    "    if counter == 0:\n",
    "        train_model()\n",
    "    \n",
    "    # Incrementing the counter for each prediction call\n",
    "    counter += 1\n",
    "    \n",
    "    # Prepare test data and drop columns\n",
    "    test_df = fe.load_and_process(Config.test_data_path, drop_cols=['num_wins_agent1', 'num_draws_agent1', 'num_losses_agent1'])\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = md.predict(test_df)\n",
    "    \n",
    "    # Assign predictions to the submission DataFrame\n",
    "    return submission.with_columns(pl.Series('utility_agent1', predictions))\n",
    "\n",
    "\n",
    "inference_server = mcts_inference_server.MCTSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (Config.test_data_path, Config.submission_path)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58f3112-3598-4672-8439-2b44e02f715d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'polars'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpolars\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrdinalEncoder\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'polars'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import lightgbm as lgb\n",
    "import kaggle_evaluation.mcts_inference_server\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to drop columns with a single unique value\n",
    "def drop_single_value_cols(df):\n",
    "    single_value_cols = [col for col in df.columns if df[col].n_unique() == 1]\n",
    "    return df.drop(single_value_cols)\n",
    "\n",
    "# Model training function\n",
    "def train_model():\n",
    "    global obj_cols, enc, lgb_model, train_cols\n",
    "\n",
    "    # Load training data\n",
    "    train = pl.read_csv('/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv')\n",
    "    \n",
    "    # Target variable\n",
    "    y_train = train['utility_agent1']\n",
    "    \n",
    "    # Drop columns with single values in the train dataset\n",
    "    train = drop_single_value_cols(train)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    cols_to_drop = ['num_draws_agent1', 'num_losses_agent1', 'num_wins_agent1', 'utility_agent1']\n",
    "    train = train.drop(cols_to_drop)\n",
    "\n",
    "    # Encode categorical columns\n",
    "    obj_cols = train.select(pl.col(pl.String)).columns\n",
    "    enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-999, encoded_missing_value=-9999)\n",
    "    enc.fit(train[obj_cols])\n",
    "\n",
    "    # This will transform the categorical columns in the training data\n",
    "    train_transformed = enc.transform(train[obj_cols])\n",
    "    for e, c in enumerate(obj_cols):\n",
    "        train = train.with_columns(pl.Series(c, train_transformed[:, e]))\n",
    "\n",
    "    # Storing the train columns for comparison with the test dataset\n",
    "    train_cols = set(train.columns) \n",
    "\n",
    "    # Prepare training data\n",
    "    X_train = train.to_pandas()\n",
    "    y_train = y_train.to_pandas()\n",
    "\n",
    "    # Define LightGBM dataset\n",
    "    lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    # LightGBM model parameters\n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        n_estimators=200, \n",
    "        learning_rate=0.1, \n",
    "        max_depth=20, \n",
    "        num_leaves=70, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Model training\n",
    "    lgb_model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        eval_metric='mse'  # Set the metric to MSE\n",
    "    )\n",
    "\n",
    "\n",
    "counter = 0  # Initializing counter\n",
    "\n",
    "def preprocess_and_predict(df: pl.DataFrame, is_training: bool):\n",
    "    global obj_cols, enc, train_cols\n",
    "\n",
    "    # Drop columns with single values\n",
    "    #df = drop_single_value_cols(df)\n",
    "\n",
    "    if is_training:\n",
    "        # Encoding categorical columns during training\n",
    "        enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-999, encoded_missing_value=-9999)\n",
    "        enc.fit(df[obj_cols])\n",
    "        \n",
    "        # This will transform the categorical columns\n",
    "        df_transformed = enc.transform(df[obj_cols])\n",
    "        for e, c in enumerate(obj_cols):\n",
    "            df = df.with_columns(pl.Series(c, df_transformed[:, e]))\n",
    "        \n",
    "        # Storing the columns for future predictions\n",
    "        train_cols = set(df.columns)\n",
    "    else:\n",
    "        # Applying the same encoding to the test data\n",
    "        df_transformed = enc.transform(df[obj_cols])\n",
    "        for e, c in enumerate(obj_cols):\n",
    "            df = df.with_columns(pl.Series(c, df_transformed[:, e]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def predict(test, submission):\n",
    "    global counter, obj_cols, train_cols, enc, lgb_model\n",
    "\n",
    "    try:\n",
    "        if counter == 0:\n",
    "            train_model()\n",
    "        counter += 1\n",
    "\n",
    "        # Loading of the test data\n",
    "        test = pl.read_csv('/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv')\n",
    "        #test = drop_single_value_cols(test)\n",
    "\n",
    "        # Droppig columns in test dataset but not present in training data\n",
    "        test_cols = set(test.columns)\n",
    "        extra_cols = test_cols - train_cols\n",
    "        test = test.drop(list(extra_cols))\n",
    "\n",
    "        # This will apply the same encoding to the test data\n",
    "        test_transformed = enc.transform(test[obj_cols])\n",
    "        for e, c in enumerate(obj_cols):\n",
    "            test = test.with_columns(pl.Series(c, test_transformed[:, e]))\n",
    "\n",
    "        # Prepare the test data for prediction\n",
    "        X_test = test.to_pandas()\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = lgb_model.predict(X_test)\n",
    "\n",
    "        # Update the submission DataFrame with predictions\n",
    "        submission = submission.with_columns(pl.Series('utility_agent1', predictions))\n",
    "\n",
    "        # Save the predictions as 'submission.parquet'\n",
    "        submission.write_parquet('submission.parquet')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "    return submission\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b89169-6cb3-409f-8afd-88db0bb30050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import kaggle_evaluation.mcts_inference_server\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to competition files\n",
    "comp_path = Path('/kaggle/input/um-game-playing-strength-of-mcts-variants')\n",
    "\n",
    "target = 'utility_agent1'\n",
    "counter = 0\n",
    "\n",
    "# Load training data\n",
    "train = pl.read_csv(comp_path / 'train.csv')\n",
    "y_train = train[target]\n",
    "\n",
    "cols_to_drop = ['num_draws_agent1', 'num_losses_agent1', 'num_wins_agent1', target]\n",
    "train = train.drop(cols_to_drop)\n",
    "\n",
    "# Encode categorical columns\n",
    "obj_cols = train.select(pl.col(pl.String)).columns\n",
    "enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-999, encoded_missing_value=-9999)\n",
    "enc.fit(train[obj_cols])\n",
    "\n",
    "train_transformed = enc.transform(train[obj_cols])\n",
    "for e, c in enumerate(obj_cols):\n",
    "    train = train.with_columns(pl.Series(c, train_transformed[:, e]))\n",
    "\n",
    "# Define models to test with Bagging\n",
    "models = {\n",
    "    'rf': RandomForestRegressor(),\n",
    "    'gbr': GradientBoostingRegressor(),\n",
    "}\n",
    "\n",
    "# Define parameter grids for grid search\n",
    "param_grid = {\n",
    "    'rf': {'n_estimators': [100, 200], 'max_depth': [5, 10]},\n",
    "    'gbr': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]},\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for each model\n",
    "best_models = {}\n",
    "for model_name in models:\n",
    "    grid = GridSearchCV(BaggingRegressor(base_estimator=models[model_name], n_jobs=-1),\n",
    "                        param_grid[model_name], cv=3, scoring='neg_mean_squared_error')\n",
    "    grid.fit(train, y_train)\n",
    "    best_models[model_name] = grid.best_estimator_\n",
    "\n",
    "    # Output best parameters\n",
    "    print(f\"Best parameters for {model_name}: {grid.best_params_}\")\n",
    "\n",
    "# Select the best model based on cross-validation score\n",
    "best_model_name = max(best_models, key=lambda m: -grid.best_score_)\n",
    "best_model = best_models[best_model_name]\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'best_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daca1de-dc9c-4ce7-b80e-ae1a1282c831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafa4f22-16cf-4703-b72b-12dc5f8b4683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8503052-7d86-4fd3-86c1-09cefad15a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "counter = 0\n",
    "best_model = None\n",
    "\n",
    "# Prediction function\n",
    "def predict(test: pl.DataFrame, submission: pl.DataFrame):\n",
    "    global counter, best_model\n",
    "    if counter == 0:\n",
    "        # Load the pre-trained model during the first call\n",
    "        best_model = joblib.load('best_model.joblib')\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "    # Transform test data\n",
    "    test_transformed = enc.transform(test[obj_cols])\n",
    "    for e, c in enumerate(obj_cols):\n",
    "        test = test.with_columns(pl.Series(c, test_transformed[:, e]))\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = best_model.predict(test)\n",
    "\n",
    "    # Update the submission DataFrame with predictions\n",
    "    submission = submission.with_columns(pl.Series(target, predictions))\n",
    "\n",
    "    # Save the predictions as 'submission.parquet'\n",
    "    submission.write_parquet('submission.parquet')\n",
    "\n",
    "    # Return the submission DataFrame\n",
    "    return submission\n",
    "\n",
    "# Initialize the inference server\n",
    "inference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv',\n",
    "            '/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20532fe1-ef18-4596-b798-115bd39d17c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65931a95-eb9d-4b7a-aaae-e331bb4436b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27125e25-60ec-4648-9ee8-258218917c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import kaggle_evaluation.mcts_inference_server\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to competition files\n",
    "comp_path = Path('/kaggle/input/um-game-playing-strength-of-mcts-variants')\n",
    "\n",
    "target = 'utility_agent1'\n",
    "counter = 0\n",
    "\n",
    "# Model training function\n",
    "def train_model():\n",
    "    global obj_cols, enc, rf\n",
    "\n",
    "    # Load training data\n",
    "    train = pl.read_csv(comp_path / 'train.csv')\n",
    "    y_train = train[target]\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    cols_to_drop = ['num_draws_agent1', 'num_losses_agent1', 'num_wins_agent1', target]\n",
    "    train = train.drop(cols_to_drop)\n",
    "    \n",
    "    # Encode categorical columns\n",
    "    obj_cols = train.select(pl.col(pl.String)).columns\n",
    "    enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-999, encoded_missing_value=-9999)\n",
    "    enc.fit(train[obj_cols])\n",
    "    \n",
    "    # Transform the categorical data\n",
    "    train_transformed = enc.transform(train[obj_cols])\n",
    "    for e, c in enumerate(obj_cols):\n",
    "        train = train.with_columns(pl.Series(c, train_transformed[:, e]))\n",
    "    \n",
    "    # Train Random Forest Regressor\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=5, n_jobs=-1)\n",
    "    rf.fit(train, y_train)\n",
    "\n",
    "# Prediction function\n",
    "def predict(test: pl.DataFrame, submission: pl.DataFrame):\n",
    "    global counter\n",
    "    if counter == 0:\n",
    "        # Perform model training during the first call\n",
    "        train_model()\n",
    "    counter += 1\n",
    "\n",
    "    # Transform test data\n",
    "    test_transformed = enc.transform(test[obj_cols])\n",
    "    for e, c in enumerate(obj_cols):\n",
    "        test = test.with_columns(pl.Series(c, test_transformed[:, e]))\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = rf.predict(test)\n",
    "\n",
    "    # Update the submission DataFrame with predictions\n",
    "    submission = submission.with_columns(pl.Series(target, predictions))\n",
    "\n",
    "    # Save the predictions as 'submission.parquet'\n",
    "    submission.write_parquet('submission.parquet')\n",
    "\n",
    "    # Return the submission DataFrame\n",
    "    return submission\n",
    "\n",
    "# Initialize the inference server\n",
    "inference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv',\n",
    "            '/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv'\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e62bbe-76a1-40ae-b039-bf1847f26a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe showing Only the requested statistics (mean, minimum and maximum). Then, transpose the table.\n",
    "\n",
    "df.describe().loc[['mean','min','max']].T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
