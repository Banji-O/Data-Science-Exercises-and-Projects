{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"modelInstanceVersion","sourceId":2622,"databundleVersionId":4910250,"modelInstanceId":1899},{"sourceType":"modelInstanceVersion","sourceId":2938,"databundleVersionId":4932971,"modelInstanceId":2180}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><h1><b>Introduction to BERTH</b></h1></center>\n<center><h2>Bidirectional Encoder Representations from Transformers</h2></center>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras as ks\n\nimport tensorflow_hub as hub\nimport tensorflow_text as text\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-11-04T04:24:24.210835Z","iopub.execute_input":"2024-11-04T04:24:24.211265Z","iopub.status.idle":"2024-11-04T04:24:24.538069Z","shell.execute_reply.started":"2024-11-04T04:24:24.211228Z","shell.execute_reply":"2024-11-04T04:24:24.537084Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Below syntax is from tensorflow web page\n\nmodel = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\nembeddings = model([\"The rain in Spain.\", \"falls\",\n                  \"mainly\", \"In the plain!\"])\n\nprint(embeddings.shape)  #(4,128)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T04:16:52.832233Z","iopub.execute_input":"2024-11-04T04:16:52.833396Z","iopub.status.idle":"2024-11-04T04:16:53.870184Z","shell.execute_reply.started":"2024-11-04T04:16:52.833338Z","shell.execute_reply":"2024-11-04T04:16:53.869052Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(4, 128)\n","output_type":"stream"}]},{"cell_type":"code","source":"preprocess_url = \"https://kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-preprocess/3\"\nencoder_url = \"https://www.kaggle.com/models/tensorflow/bert/TensorFlow2/bert-en-uncased-l-10-h-128-a-2/2\"","metadata":{"execution":{"iopub.status.busy":"2024-11-04T04:29:16.802586Z","iopub.execute_input":"2024-11-04T04:29:16.803014Z","iopub.status.idle":"2024-11-04T04:29:16.808240Z","shell.execute_reply.started":"2024-11-04T04:29:16.802975Z","shell.execute_reply":"2024-11-04T04:29:16.807157Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"bert_preprocess_model = hub.KerasLayer(preprocess_url)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T04:38:07.616733Z","iopub.execute_input":"2024-11-04T04:38:07.617186Z","iopub.status.idle":"2024-11-04T04:38:10.703409Z","shell.execute_reply.started":"2024-11-04T04:38:07.617144Z","shell.execute_reply":"2024-11-04T04:38:10.702185Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# To preprocess sentences\ntext_test = ['nice movie indeed', 'I love Python programming']\ntext_preprocessed = bert_preprocess_model(text_test)\n\n# To see the keys\ntext_preprocessed.keys()","metadata":{"execution":{"iopub.status.busy":"2024-11-04T04:38:13.316522Z","iopub.execute_input":"2024-11-04T04:38:13.316962Z","iopub.status.idle":"2024-11-04T04:38:13.601740Z","shell.execute_reply.started":"2024-11-04T04:38:13.316921Z","shell.execute_reply":"2024-11-04T04:38:13.600558Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"dict_keys(['input_mask', 'input_word_ids', 'input_type_ids'])"},"metadata":{}}]},{"cell_type":"code","source":"text_preprocessed['input_mask']  # shape(2, 128) means 2 sentences processed. it uses CLS and SEP special token at the beginning and end of the sentence ","metadata":{"execution":{"iopub.status.busy":"2024-11-04T04:40:07.308190Z","iopub.execute_input":"2024-11-04T04:40:07.308624Z","iopub.status.idle":"2024-11-04T04:40:07.318170Z","shell.execute_reply.started":"2024-11-04T04:40:07.308585Z","shell.execute_reply":"2024-11-04T04:40:07.316945Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\narray([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n      dtype=int32)>"},"metadata":{}}]},{"cell_type":"code","source":"text_preprocessed['input_type_ids']  # This is used on multiple sentences","metadata":{"execution":{"iopub.status.busy":"2024-11-04T04:44:45.048798Z","iopub.execute_input":"2024-11-04T04:44:45.050132Z","iopub.status.idle":"2024-11-04T04:44:45.058364Z","shell.execute_reply.started":"2024-11-04T04:44:45.050061Z","shell.execute_reply":"2024-11-04T04:44:45.057181Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\narray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n      dtype=int32)>"},"metadata":{}}]},{"cell_type":"code","source":"text_preprocessed['input_word_ids']  # This creates unique id fro each word","metadata":{"execution":{"iopub.status.busy":"2024-11-04T04:46:14.549291Z","iopub.execute_input":"2024-11-04T04:46:14.549787Z","iopub.status.idle":"2024-11-04T04:46:14.558644Z","shell.execute_reply.started":"2024-11-04T04:46:14.549744Z","shell.execute_reply":"2024-11-04T04:46:14.557517Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\narray([[  101,  3835,  3185,  5262,   102,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0],\n       [  101,  1045,  2293, 18750,  4730,   102,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0]], dtype=int32)>"},"metadata":{}}]},{"cell_type":"code","source":"# Creatng a layer with encoder url\nbert_model = hub.KerasLayer(encoder_url)\n\nbert_results = bert_model(text_preprocessed)\n\n# Keys of encoder layer\nbert_results.keys()","metadata":{"execution":{"iopub.status.busy":"2024-11-04T05:31:00.955296Z","iopub.execute_input":"2024-11-04T05:31:00.955862Z","iopub.status.idle":"2024-11-04T05:31:17.097654Z","shell.execute_reply.started":"2024-11-04T05:31:00.955819Z","shell.execute_reply":"2024-11-04T05:31:17.096216Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"dict_keys(['sequence_output', 'pooled_output', 'default', 'encoder_outputs'])"},"metadata":{}}]},{"cell_type":"code","source":"# Checking the pooled_output key\nbert_results['pooled_output']  # The output embedding vectors can be used in text classification task","metadata":{"execution":{"iopub.status.busy":"2024-11-04T05:35:27.990527Z","iopub.execute_input":"2024-11-04T05:35:27.990987Z","iopub.status.idle":"2024-11-04T05:35:28.001865Z","shell.execute_reply.started":"2024-11-04T05:35:27.990948Z","shell.execute_reply":"2024-11-04T05:35:28.000576Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(2, 128), dtype=float32, numpy=\narray([[-9.61583436e-01,  9.82990801e-01,  6.71520680e-02,\n        -9.77145851e-01, -9.96612847e-01,  4.21944037e-02,\n        -7.20781744e-01,  6.94600865e-02,  6.30466163e-01,\n        -8.44422698e-01, -9.30527329e-01,  5.36174357e-01,\n         8.93691242e-01,  9.97095942e-01,  7.85159171e-02,\n         8.94847691e-01, -9.99662936e-01,  6.46769106e-01,\n        -7.32644975e-01,  9.57778513e-01, -9.80164707e-01,\n        -8.61537874e-01, -7.56168365e-01,  9.29833889e-01,\n        -9.41975057e-01,  9.18909550e-01, -2.68500805e-01,\n        -9.99269664e-01,  1.17457666e-01, -8.98820162e-01,\n         9.89692032e-01,  9.61469352e-01,  9.82462049e-01,\n         9.33466434e-01,  8.38703573e-01, -3.61137576e-02,\n        -9.61118698e-01,  1.01809995e-02,  5.61180174e-01,\n         3.78839612e-01, -9.94660020e-01, -8.68889213e-01,\n         1.10555649e-01,  9.99908090e-01, -1.88111380e-01,\n        -1.88300222e-01, -2.27432787e-01, -8.82381916e-01,\n         9.76414561e-01,  9.99302208e-01, -2.85161257e-01,\n        -8.85916173e-01,  1.92312166e-01,  6.77957475e-01,\n         3.35616358e-02, -8.12915802e-01,  1.83975011e-01,\n         3.20066437e-02, -8.58979404e-01,  9.76898193e-01,\n        -9.98683333e-01, -5.81674099e-01,  5.81552982e-01,\n        -4.99231629e-02, -8.35291386e-01,  9.97506201e-01,\n         3.44599299e-02, -9.22366083e-01, -5.51890465e-04,\n        -8.58245254e-01, -9.98203158e-01,  7.88791925e-02,\n        -7.56360352e-01,  1.91932102e-03,  9.99752223e-01,\n        -5.15031040e-01,  4.14854363e-02, -6.05720766e-02,\n         9.52537298e-01,  1.41091570e-01,  1.00067705e-02,\n         9.98775423e-01, -9.56732154e-01,  9.55396891e-01,\n         7.09951758e-01,  8.99509013e-01,  2.99156979e-02,\n         2.29252912e-02, -9.70877945e-01, -1.59708217e-01,\n         9.53843474e-01,  8.52992296e-01, -9.27973330e-01,\n         9.07392263e-01, -5.62512219e-01, -8.07555258e-01,\n         5.72897971e-01,  9.21838641e-01, -8.15266371e-02,\n         4.77076620e-02,  1.86538666e-01, -9.71178889e-01,\n        -9.29245770e-01, -8.85698557e-01,  9.84842420e-01,\n         9.80754912e-01,  3.36829156e-01, -8.38373899e-01,\n        -5.48395514e-01, -9.28341508e-01,  9.99453247e-01,\n        -3.36627901e-01,  8.39870572e-01,  9.88217413e-01,\n        -9.84666049e-01, -9.73674417e-01, -6.00755453e-01,\n         4.57791299e-01, -2.93841451e-01, -9.50930059e-01,\n         1.24632083e-01, -9.95446742e-01, -9.02923763e-01,\n         3.69310677e-02, -4.70977724e-01,  9.98495817e-01,\n        -5.03255844e-01,  5.10769896e-02],\n       [-8.04073036e-01,  9.90769386e-01,  3.53648551e-02,\n        -9.14522171e-01, -9.87278759e-01,  3.07293832e-01,\n        -5.13170958e-01,  1.02655426e-01,  9.76709187e-01,\n        -4.45094436e-01, -9.55273271e-01,  6.14130139e-01,\n         9.56513703e-01,  9.60232854e-01, -6.47526681e-02,\n         8.77278805e-01, -9.98603582e-01, -4.74239558e-01,\n        -8.72795880e-01,  9.78545845e-01, -9.31409001e-01,\n        -7.57344306e-01, -7.76212394e-01,  9.65374887e-01,\n        -9.70437944e-01,  8.98523629e-01, -1.86477259e-01,\n        -9.96744156e-01, -7.28569865e-01, -9.73153234e-01,\n         9.75300431e-01,  9.87888277e-01,  9.88917530e-01,\n         8.98947358e-01,  7.04684436e-01,  1.65922921e-02,\n        -9.79354858e-01, -7.93521166e-01,  3.64658803e-01,\n         2.82847196e-01, -9.10628557e-01, -8.96304369e-01,\n         8.86940062e-02,  9.99371886e-01, -7.99137592e-01,\n        -8.81705761e-01, -4.93498772e-01, -8.33582580e-01,\n         9.40448523e-01,  9.93273020e-01, -5.57348788e-01,\n        -9.93993044e-01,  1.16041318e-01, -3.89228076e-01,\n        -9.90897715e-02, -8.92621875e-01,  1.71366632e-01,\n         8.16227272e-02, -9.58528996e-01,  8.92956853e-01,\n        -9.98861551e-01, -8.00628543e-01,  4.06371839e-02,\n        -5.32987677e-02, -9.12404001e-01,  9.92454886e-01,\n         2.68116239e-02, -9.95910704e-01, -1.43082544e-01,\n        -7.03969896e-01, -9.83511925e-01,  9.42265987e-02,\n        -8.82951200e-01, -1.22419205e-02,  9.99159873e-01,\n        -2.28294253e-01,  5.15894257e-02, -1.67598546e-01,\n         8.39051664e-01,  1.70560122e-01,  4.94176358e-01,\n         9.91302013e-01, -9.45613921e-01,  8.83428395e-01,\n         7.16777146e-01,  9.11784291e-01,  1.05661824e-01,\n         2.90672742e-02, -7.50256777e-01, -1.72569960e-01,\n         9.51991618e-01,  9.77186918e-01, -9.12028611e-01,\n         4.03408229e-01, -8.69114697e-01, -6.46672964e-01,\n         3.99358809e-01,  9.12079453e-01, -1.28079847e-01,\n        -1.23825530e-02,  4.02061880e-01, -9.01134193e-01,\n        -9.90269303e-01, -9.90933955e-01,  9.87271428e-01,\n         9.96842265e-01,  9.17698085e-01, -8.41336071e-01,\n        -5.36296785e-01, -9.02621746e-01,  9.97242451e-01,\n        -8.51288736e-01,  8.25740159e-01,  9.12909329e-01,\n        -7.28057981e-01, -9.60862756e-01, -9.89209354e-01,\n        -4.02796865e-01, -5.99602163e-01, -8.37571263e-01,\n        -4.37680215e-01, -9.75260794e-01, -9.67087805e-01,\n         7.89156780e-02, -1.88271314e-01,  9.90743876e-01,\n        -7.38201201e-01,  2.59411111e-02]], dtype=float32)>"},"metadata":{}}]},{"cell_type":"code","source":"# The sequence output key\nbert_results['sequence_output']  # These are the initial Berth embedding vectors showing the sizes (2, 128, 128)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T05:56:25.391410Z","iopub.execute_input":"2024-11-04T05:56:25.391938Z","iopub.status.idle":"2024-11-04T05:56:25.401705Z","shell.execute_reply.started":"2024-11-04T05:56:25.391890Z","shell.execute_reply":"2024-11-04T05:56:25.400605Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(2, 128, 128), dtype=float32, numpy=\narray([[[-2.5010061e-01,  6.2538946e-01,  1.6460221e+00, ...,\n          1.2799288e+00, -1.6682668e-01, -2.2829823e-01],\n        [-1.1235907e+00, -8.1793207e-01,  3.8127321e-01, ...,\n          1.5564997e+00,  1.2363948e+00, -2.7739465e-01],\n        [-1.3074750e+00, -2.6063615e-01,  1.5051280e+00, ...,\n          1.3184564e-01,  1.7667718e-01, -4.1672823e-01],\n        ...,\n        [-2.3766859e-01,  5.8498603e-01,  7.6011205e-01, ...,\n          1.8044731e-01,  7.6439792e-01,  2.4921894e-01],\n        [-2.9944208e-01,  5.3079379e-01,  8.3755362e-01, ...,\n         -4.1594442e-02,  5.0408024e-01,  3.6551052e-01],\n        [-3.2004949e-01,  6.1789536e-01,  3.0612543e-01, ...,\n          2.7973158e-02,  5.6527239e-01,  2.1248914e-01]],\n\n       [[ 8.2462144e-01,  8.3597130e-01,  8.6861706e-01, ...,\n          5.6793845e-01,  8.9088577e-01, -2.2193362e-01],\n        [-4.3414891e-02, -1.0212824e-02,  3.4325612e-01, ...,\n          7.5379980e-01,  5.2102560e-01,  7.1276939e-01],\n        [-1.1730777e+00,  5.9087425e-01,  4.4501299e-01, ...,\n          1.9331857e+00, -1.1777316e-01,  2.8396261e-01],\n        ...,\n        [ 1.0318278e-01,  3.0710077e-01,  4.9424642e-01, ...,\n         -6.8497159e-02,  1.0320106e+00,  8.5885316e-02],\n        [-1.6203535e-01,  3.6506754e-01,  6.5589166e-01, ...,\n         -2.3337874e-01,  7.7551740e-01,  2.8598422e-01],\n        [-2.0620227e-04,  2.7271071e-01,  5.9332207e-02, ...,\n         -4.9347627e-01,  3.3050385e-01,  3.8111454e-01]]], dtype=float32)>"},"metadata":{}}]},{"cell_type":"code","source":"# The length of the encoder output\nlen(bert_results['encoder_outputs'])  # Thi is the length of the BERTH base i.e the model used. 10 signifies that small model is being used","metadata":{"execution":{"iopub.status.busy":"2024-11-04T06:00:29.473523Z","iopub.execute_input":"2024-11-04T06:00:29.473966Z","iopub.status.idle":"2024-11-04T06:00:29.481865Z","shell.execute_reply.started":"2024-11-04T06:00:29.473925Z","shell.execute_reply":"2024-11-04T06:00:29.480404Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}]},{"cell_type":"code","source":"# Contents of the first encoder or layer\nbert_results['encoder_outputs'][0]","metadata":{"execution":{"iopub.status.busy":"2024-11-04T06:03:05.007749Z","iopub.execute_input":"2024-11-04T06:03:05.008202Z","iopub.status.idle":"2024-11-04T06:03:05.018375Z","shell.execute_reply.started":"2024-11-04T06:03:05.008164Z","shell.execute_reply":"2024-11-04T06:03:05.017068Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(2, 128, 128), dtype=float32, numpy=\narray([[[ 0.38996482,  0.5514192 ,  0.21972291, ..., -0.08233654,\n         -0.21757811,  0.3589819 ],\n        [-0.28004622, -2.0411665 , -0.97132045, ...,  0.41115627,\n          0.78592765,  0.667929  ],\n        [-0.14401902, -0.54543054,  0.2831009 , ..., -1.7191359 ,\n         -0.69747424,  0.35127097],\n        ...,\n        [ 1.9506999 ,  1.9278376 ,  1.3637809 , ..., -0.05854023,\n          0.05594981,  1.5992849 ],\n        [ 1.7430557 ,  1.9147065 ,  1.3637424 , ..., -0.6371481 ,\n         -0.6740017 ,  1.736562  ],\n        [ 1.36594   ,  1.9274958 ,  0.6786979 , ..., -1.1624889 ,\n         -1.3285384 ,  1.6973263 ]],\n\n       [[ 0.31130934,  0.52738786,  0.19879341, ..., -0.03409324,\n         -0.21684176,  0.35590625],\n        [ 0.82905704, -0.2761583 , -0.925563  , ...,  0.80140495,\n         -0.27236938,  0.90460366],\n        [ 0.21057871, -0.50038075, -0.10756762, ...,  1.2260262 ,\n         -2.4162629 ,  1.0626483 ],\n        ...,\n        [ 1.7890846 ,  1.8640648 ,  1.2574302 , ...,  0.15321672,\n         -0.0280841 ,  1.305578  ],\n        [ 1.5999081 ,  1.8675699 ,  1.2619469 , ..., -0.39463422,\n         -0.7656237 ,  1.4657141 ],\n        [ 1.2353398 ,  1.8967637 ,  0.58449996, ..., -0.88372433,\n         -1.43938   ,  1.4827405 ]]], dtype=float32)>"},"metadata":{}}]},{"cell_type":"code","source":"# To show that the last layer of the encoder and the sequence output are the same\nbert_results['encoder_outputs'][-1] == bert_results['sequence_output']","metadata":{"execution":{"iopub.status.busy":"2024-11-04T06:05:42.120612Z","iopub.execute_input":"2024-11-04T06:05:42.121175Z","iopub.status.idle":"2024-11-04T06:05:42.130464Z","shell.execute_reply.started":"2024-11-04T06:05:42.121127Z","shell.execute_reply":"2024-11-04T06:05:42.129198Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(2, 128, 128), dtype=bool, numpy=\narray([[[ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        ...,\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True]],\n\n       [[ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        ...,\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True]]])>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}