{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><h1><b>Quantization</b></h1></center>\n\nThis is the process of reducing model size so that it can run smoothly and efficiently on edge devices like mobile phones, smart watches, etc.\n\nTwo ways of performing quantization\n- Post training quantization - tf.lite convert is used to covert built model to smaller model. If quantization is applied when converting it makes the model size to be smaller. The weights of the model is converted from float to integer.\n- Quantization aware training: quantized model function is applied on tf_model and the model is retrained or fine-tuned just like transfer learning. This model is more accurate. Both weights and activations are converted to integer from float","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-18T11:52:38.168427Z","iopub.execute_input":"2024-11-18T11:52:38.169047Z","iopub.status.idle":"2024-11-18T11:52:39.422301Z","shell.execute_reply.started":"2024-11-18T11:52:38.169008Z","shell.execute_reply":"2024-11-18T11:52:39.421129Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:52:39.424380Z","iopub.execute_input":"2024-11-18T11:52:39.424979Z","iopub.status.idle":"2024-11-18T11:52:52.899661Z","shell.execute_reply.started":"2024-11-18T11:52:39.424929Z","shell.execute_reply":"2024-11-18T11:52:52.898531Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models \nimport matplotlib.pyplot as plt\nimport seaborn as sb\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:52:52.900957Z","iopub.execute_input":"2024-11-18T11:52:52.901573Z","iopub.status.idle":"2024-11-18T11:52:53.646905Z","shell.execute_reply.started":"2024-11-18T11:52:52.901532Z","shell.execute_reply":"2024-11-18T11:52:53.645955Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"(X_train, y_train), (X_test, y_test)  = keras.datasets.mnist.load_data()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:52:53.649792Z","iopub.execute_input":"2024-11-18T11:52:53.650592Z","iopub.status.idle":"2024-11-18T11:52:55.369092Z","shell.execute_reply.started":"2024-11-18T11:52:53.650539Z","shell.execute_reply":"2024-11-18T11:52:55.367927Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"len(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:52:55.370578Z","iopub.execute_input":"2024-11-18T11:52:55.371026Z","iopub.status.idle":"2024-11-18T11:52:55.380698Z","shell.execute_reply.started":"2024-11-18T11:52:55.370976Z","shell.execute_reply":"2024-11-18T11:52:55.379561Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"60000"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:52:55.382237Z","iopub.execute_input":"2024-11-18T11:52:55.382697Z","iopub.status.idle":"2024-11-18T11:52:55.395158Z","shell.execute_reply.started":"2024-11-18T11:52:55.382649Z","shell.execute_reply":"2024-11-18T11:52:55.393724Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(60000, 28, 28)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"len(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:52:55.398643Z","iopub.execute_input":"2024-11-18T11:52:55.399114Z","iopub.status.idle":"2024-11-18T11:52:55.407088Z","shell.execute_reply.started":"2024-11-18T11:52:55.399064Z","shell.execute_reply":"2024-11-18T11:52:55.405945Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"10000"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:52:55.408613Z","iopub.execute_input":"2024-11-18T11:52:55.408956Z","iopub.status.idle":"2024-11-18T11:52:55.419723Z","shell.execute_reply.started":"2024-11-18T11:52:55.408911Z","shell.execute_reply":"2024-11-18T11:52:55.418352Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(10000, 28, 28)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"plt.matshow(X_train[0]);","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:52:55.421254Z","iopub.execute_input":"2024-11-18T11:52:55.421734Z","iopub.status.idle":"2024-11-18T11:52:56.011086Z","shell.execute_reply.started":"2024-11-18T11:52:55.421696Z","shell.execute_reply":"2024-11-18T11:52:56.009675Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 480x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Scaling the data with the highest possible value in the data\nX_train = X_train/255\nX_test = X_test/255","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:52:56.016327Z","iopub.execute_input":"2024-11-18T11:52:56.017144Z","iopub.status.idle":"2024-11-18T11:52:56.210650Z","shell.execute_reply.started":"2024-11-18T11:52:56.017082Z","shell.execute_reply":"2024-11-18T11:52:56.209637Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Define the model using the Input layer for the first layer\nmodel = keras.Sequential([\n    keras.layers.Input(shape=(28, 28)),\n    keras.layers.Flatten(),\n    keras.layers.Dense(100, activation='relu'),\n    keras.layers.Dense(10, activation='sigmoid')\n])\n\n# Print the model summary to verify the structure\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T11:52:56.211820Z","iopub.execute_input":"2024-11-18T11:52:56.212156Z","iopub.status.idle":"2024-11-18T11:52:56.305746Z","shell.execute_reply.started":"2024-11-18T11:52:56.212119Z","shell.execute_reply":"2024-11-18T11:52:56.304730Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m78,500\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# This will compile the neural network\nmodel.compile(optimizer='adam',  # It allows efficient training\n              loss='sparse_categorical_crossentropy', # This is used because the output is categorical. there are other options that can be used\n              metrics=['accuracy']\n             )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T11:52:56.306971Z","iopub.execute_input":"2024-11-18T11:52:56.307322Z","iopub.status.idle":"2024-11-18T11:52:56.324068Z","shell.execute_reply.started":"2024-11-18T11:52:56.307263Z","shell.execute_reply":"2024-11-18T11:52:56.322872Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Buildig the model\nmodel.fit(X_train, y_train, epochs=5) # epochs mean number of iteration the neural network will run the training","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T11:53:12.937259Z","iopub.execute_input":"2024-11-18T11:53:12.937731Z","iopub.status.idle":"2024-11-18T11:53:32.345564Z","shell.execute_reply.started":"2024-11-18T11:53:12.937690Z","shell.execute_reply":"2024-11-18T11:53:32.344185Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8752 - loss: 0.4450\nEpoch 2/5\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9611 - loss: 0.1354\nEpoch 3/5\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.0943\nEpoch 4/5\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.0654\nEpoch 5/5\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0535\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7e4c9d30d060>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Evaluatig the accuracy of the model on test dataset\nmodel.evaluate(X_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T11:53:42.505491Z","iopub.execute_input":"2024-11-18T11:53:42.505920Z","iopub.status.idle":"2024-11-18T11:53:43.139244Z","shell.execute_reply.started":"2024-11-18T11:53:42.505880Z","shell.execute_reply":"2024-11-18T11:53:43.138175Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9708 - loss: 0.0969\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[0.08405108749866486, 0.9746999740600586]"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# Save the model in the SavedModel format using the new export method\nmodel.export('./saved_model')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T11:53:47.629629Z","iopub.execute_input":"2024-11-18T11:53:47.630041Z","iopub.status.idle":"2024-11-18T11:53:47.972928Z","shell.execute_reply.started":"2024-11-18T11:53:47.630002Z","shell.execute_reply":"2024-11-18T11:53:47.971501Z"}},"outputs":[{"name":"stdout","text":"Saved artifact at './saved_model'. The following endpoints are available:\n\n* Endpoint 'serve'\n  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='keras_tensor')\nOutput Type:\n  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\nCaptures:\n  138867518720832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138867518721712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138867518720480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  138867518718544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Post Training Quantization","metadata":{}},{"cell_type":"code","source":"# Convert the SavedModel to TensorFlow Lite format\nconverter = tf.lite.TFLiteConverter.from_saved_model('./saved_model')\n\ntflite_model = converter.convert()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T11:53:51.550172Z","iopub.execute_input":"2024-11-18T11:53:51.550594Z","iopub.status.idle":"2024-11-18T11:53:51.877496Z","shell.execute_reply.started":"2024-11-18T11:53:51.550555Z","shell.execute_reply":"2024-11-18T11:53:51.876217Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nW0000 00:00:1731930831.645692      31 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\nW0000 00:00:1731930831.645768      31 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"len(tflite_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T11:53:55.704943Z","iopub.execute_input":"2024-11-18T11:53:55.705366Z","iopub.status.idle":"2024-11-18T11:53:55.712362Z","shell.execute_reply.started":"2024-11-18T11:53:55.705324Z","shell.execute_reply":"2024-11-18T11:53:55.711155Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"319940"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# Convert the SavedModel to TensorFlow Lite format\nconverter = tf.lite.TFLiteConverter.from_saved_model('./saved_model')\n\n# To quantize the model\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\ntflite_quant_model = converter.convert()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T11:54:02.426680Z","iopub.execute_input":"2024-11-18T11:54:02.427528Z","iopub.status.idle":"2024-11-18T11:54:02.670196Z","shell.execute_reply.started":"2024-11-18T11:54:02.427469Z","shell.execute_reply":"2024-11-18T11:54:02.669113Z"}},"outputs":[{"name":"stderr","text":"W0000 00:00:1731930842.530321      31 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\nW0000 00:00:1731930842.530355      31 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"len(tflite_quant_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T11:54:07.355551Z","iopub.execute_input":"2024-11-18T11:54:07.355939Z","iopub.status.idle":"2024-11-18T11:54:07.362967Z","shell.execute_reply.started":"2024-11-18T11:54:07.355902Z","shell.execute_reply":"2024-11-18T11:54:07.361714Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"84816"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# Save the TensorFlow Lite model to a file\nwith open('tflite_model.tflite', 'wb') as f:\n    f.write(tflite_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T11:54:16.856829Z","iopub.execute_input":"2024-11-18T11:54:16.857238Z","iopub.status.idle":"2024-11-18T11:54:16.862906Z","shell.execute_reply.started":"2024-11-18T11:54:16.857203Z","shell.execute_reply":"2024-11-18T11:54:16.861701Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Save the TensorFlow Lite model to a file\nwith open('tflite_quant_model.tflite', 'wb') as f:\n    f.write(tflite_quant_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T11:54:19.397499Z","iopub.execute_input":"2024-11-18T11:54:19.397875Z","iopub.status.idle":"2024-11-18T11:54:19.402925Z","shell.execute_reply.started":"2024-11-18T11:54:19.397842Z","shell.execute_reply":"2024-11-18T11:54:19.401946Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## Quantization Aware Training","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow-model-optimization","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T11:54:33.245370Z","iopub.execute_input":"2024-11-18T11:54:33.246214Z","iopub.status.idle":"2024-11-18T11:54:46.222376Z","shell.execute_reply.started":"2024-11-18T11:54:33.246170Z","shell.execute_reply":"2024-11-18T11:54:46.221150Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorflow-model-optimization\n  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\nRequirement already satisfied: absl-py~=1.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow-model-optimization) (1.4.0)\nRequirement already satisfied: dm-tree~=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-model-optimization) (0.1.8)\nRequirement already satisfied: numpy~=1.23 in /opt/conda/lib/python3.10/site-packages (from tensorflow-model-optimization) (1.26.4)\nRequirement already satisfied: six~=1.14 in /opt/conda/lib/python3.10/site-packages (from tensorflow-model-optimization) (1.16.0)\nDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tensorflow-model-optimization\nSuccessfully installed tensorflow-model-optimization-0.8.0\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import tensorflow_model_optimization as tfmot","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T11:54:50.116062Z","iopub.execute_input":"2024-11-18T11:54:50.116526Z","iopub.status.idle":"2024-11-18T11:54:51.816161Z","shell.execute_reply.started":"2024-11-18T11:54:50.116479Z","shell.execute_reply":"2024-11-18T11:54:51.814945Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Quantization-aware training (QAT)\nquantize_model = tfmot.quantization.keras.quantize_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T11:57:00.999030Z","iopub.execute_input":"2024-11-18T11:57:00.999454Z","iopub.status.idle":"2024-11-18T11:57:01.004820Z","shell.execute_reply.started":"2024-11-18T11:57:00.999415Z","shell.execute_reply":"2024-11-18T11:57:01.003568Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"<center><h2>Functional Model Building</h2></center>","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nimport tensorflow_model_optimization as tfmot\n\n# Define the model using the Functional API\ninputs = keras.Input(shape=(28, 28))\nx = keras.layers.Flatten()(inputs)\nx = keras.layers.Dense(100, activation='relu')(x)\noutputs = keras.layers.Dense(10, activation='sigmoid')(x)\n\n# Create the functional model\nmodel = keras.Model(inputs=inputs, outputs=outputs)\n\n# Compile the original model\nmodel.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Annotate the model for quantization\nquantize_annotate_model = tfmot.quantization.keras.quantize_annotate_model\nannotated_model = quantize_annotate_model(model)\n\n# Apply quantization-aware training\nquantize_apply = tfmot.quantization.keras.quantize_apply\nq_aware_model = quantize_apply(annotated_model)\n\n# Compile the quantization-aware model\nq_aware_model.compile(optimizer='adam',\n                      loss='sparse_categorical_crossentropy',\n                      metrics=['accuracy'])\n\n# Print the model summary\nq_aware_model.summary()\n\n# Build the model with quantization-aware training\nq_aware_model.fit(X_train, y_train, epochs=5)  # epochs mean number of iteration the neural network will run the training","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T12:24:13.858677Z","iopub.execute_input":"2024-11-18T12:24:13.859075Z","iopub.status.idle":"2024-11-18T12:24:36.742530Z","shell.execute_reply.started":"2024-11-18T12:24:13.859040Z","shell.execute_reply":"2024-11-18T12:24:36.741237Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_7\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m78,500\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.4446\nEpoch 2/5\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.1255\nEpoch 3/5\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9738 - loss: 0.0892\nEpoch 4/5\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0626\nEpoch 5/5\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0519\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7e4cb1050b80>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"# Load MNIST dataset\nmnist = tf.keras.datasets.mnist\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n\n# Normalize the input image so that each pixel value is between 0 to 1.\ntrain_images = train_images / 255.0\ntest_images = test_images / 255.0\n\n# Define the model architecture.\nmodel = keras.Sequential([\n  keras.layers.InputLayer(input_shape=(28, 28)),\n  keras.layers.Reshape(target_shape=(28, 28, 1)),\n  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n  keras.layers.Flatten(),\n  keras.layers.Dense(10)\n])\n\n# Train the digit classification model\nmodel.compile(optimizer='adam',\n              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel.fit(\n  train_images,\n  train_labels,\n  epochs=1,\n  validation_split=0.1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T13:04:06.769132Z","iopub.execute_input":"2024-11-18T13:04:06.769665Z","iopub.status.idle":"2024-11-18T13:04:19.948947Z","shell.execute_reply.started":"2024-11-18T13:04:06.769626Z","shell.execute_reply":"2024-11-18T13:04:19.947894Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8442 - loss: 0.5410 - val_accuracy: 0.9653 - val_loss: 0.1182\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7e4c46a1b250>"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"quantize_model = tfmot.quantization.keras.quantize_model\n\n# q_aware stands for for quantization aware.\nq_aware_model = quantize_model(model)\n\n# `quantize_model` requires a recompile.\nq_aware_model.compile(optimizer='adam',\n              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nq_aware_model.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"q_aware_model.fit(X_train, y_train, epochs=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# To load the in memory model\nconverter = tf.file.TFLiteConverer.from_keras_model(q_aware_model)\n\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\n\ntflite_qaware_model = converter.convert()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # Write the byte to a file\nwith open('tflte_qaware_model.tflite', 'wb') as f:\n    f.write(tflite_qaware_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}